# Fitting Simple Linear Regression to the Training set
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
install.packages("ggplot2")
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
dataset = read.csv('salary.csv')
# Splitting the dataset into the
# Training set and Test set
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
# Fitting Simple Linear Regression to the Training set
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
install.packages("ggplot2")
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
dataset = read.csv('salary.csv')
# Splitting the dataset into the
# Training set and Test set
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
# Fitting Simple Linear Regression to the Training set
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
dataset = read.csv('salary.csv')
# Splitting the dataset into the
# Training set and Test set
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
# Fitting Simple Linear Regression to the Training set
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
mae(ypred,testset$Salary)
ypred
dim(ypred)
ypred
ypred[0]
help(ypred)
class(ypred)
ypred
class(ypred)
ypred[,]
ypred[1,]
ypred
dataset
ypred
testset
ypred.values()
ypred.asNumeric()
mae(predict(lm.r),testset$Salary)
help(mae)
help(mae())
help(Metrics.mae)
?Metrics.mae
??Metrics.mae
?mae
dataset = salary
dataset = 'Salary.csv'
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
dataset = read.csv('Salary.csv',header=TRUE)
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# logistic reg
install.packages("dplyr")
# Loading package
library(dplyr)
# Summary of dataset in package
summary(mtcars)
install.packages("ROCR")       # For ROC curve to evaluate model
# Loading package
library(caTools)
library(ROCR)
# Splitting dataset
split <- sample.split(mtcars, SplitRatio = 0.8)
split
train_reg <- subset(mtcars, split == "TRUE")
test_reg <- subset(mtcars, split == "FALSE")
# Training model
logistic_model <- glm(vs ~ wt + disp,
data = train_reg,
family = "binomial")
logistic_model
# Summary
summary(logistic_model)
# Predict test data based on model
predict_reg <- predict(logistic_model,
test_reg, type = "response")
predict_reg
# Changing probabilities
predict_reg <- ifelse(predict_reg >0.5, 1, 0)
# Evaluating model accuracy
# using confusion matrix
table(test_reg$vs, predict_reg)
missing_classerr <- mean(predict_reg != test_reg$vs)
print(paste('Accuracy =', 1 - missing_classerr))
# ROC-AUC Curve
ROCPred <- prediction(predict_reg, test_reg$vs)
ROCPer <- performance(ROCPred, measure = "tpr",
x.measure = "fpr")
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc
# Plotting curve
plot(ROCPer)
plot(ROCPer, colorize = TRUE,
print.cutoffs.at = seq(0.1, by = 0.1),
main = "ROC CURVE")
abline(a = 0, b = 1)
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)
dataset = read.csv('Salary.csv',header=TRUE)
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# logistic reg
# Loading package
library(dplyr)
# Summary of dataset in package
summary(mtcars)
)       # For ROC curve to evaluate model
dataset = read.csv('Salary.csv',header=TRUE)
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# logistic reg
# Loading package
library(dplyr)
# Summary of dataset in package
summary(mtcars)
)       # For ROC curve to evaluate model
dataset = read.csv('Salary.csv',header=TRUE)
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +
ylab('Salary')
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# logistic reg
# Loading package
library(dplyr)
# Summary of dataset in package
summary(mtcars)
# For ROC curve to evaluate model
# Loading package
library(caTools)
library(ROCR)
# Splitting dataset
split <- sample.split(mtcars, SplitRatio = 0.8)
split
train_reg <- subset(mtcars, split == "TRUE")
test_reg <- subset(mtcars, split == "FALSE")
# Training model
logistic_model <- glm(vs ~ wt + disp,
data = train_reg,
family = "binomial")
logistic_model
# Summary
summary(logistic_model)
# Predict test data based on model
predict_reg <- predict(logistic_model,
test_reg, type = "response")
predict_reg
# Changing probabilities
predict_reg <- ifelse(predict_reg >0.5, 1, 0)
# Evaluating model accuracy
# using confusion matrix
table(test_reg$vs, predict_reg)
missing_classerr <- mean(predict_reg != test_reg$vs)
print(paste('Accuracy =', 1 - missing_classerr))
# ROC-AUC Curve
ROCPred <- prediction(predict_reg, test_reg$vs)
ROCPer <- performance(ROCPred, measure = "tpr",
x.measure = "fpr")
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc
# Plotting curve
plot(ROCPer)
plot(ROCPer, colorize = TRUE,
print.cutoffs.at = seq(0.1, by = 0.1),
main = "ROC CURVE")
abline(a = 0, b = 1)
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)
dataset = read.csv('Salary.csv',header=TRUE)
library(caTools)
split = sample.split(dataset$Salary, SplitRatio = 0.7)
trainingset = subset(dataset, split == TRUE)
testset = subset(dataset, split == FALSE)
lm.r= lm(formula = Salary ~ YearsExperience,
data = trainingset)
coef(lm.r)
# Predicting the Test set results
ypred = predict(lm.r, newdata = testset)
library(ggplot2)
# Visualising the Training set results
ggplot() + geom_point(aes(x = trainingset$YearsExperience,
y = trainingset$Salary), colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)), colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of experience') +
ylab('Salary')
# Visualising the Test set results
ggplot() +
geom_point(aes(x = testset$YearsExperience, y = testset$Salary),
colour = 'red') +
geom_line(aes(x = trainingset$YearsExperience,
y = predict(lm.r, newdata = trainingset)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of experience') +ylab('Salary')
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# logistic reg
# Loading package
library(dplyr)
# Summary of dataset in package
summary(mtcars)
# For ROC curve to evaluate model
# Loading package
library(caTools)
library(ROCR)
# Splitting dataset
split <- sample.split(mtcars, SplitRatio = 0.8)
split
train_reg <- subset(mtcars, split == "TRUE")
test_reg <- subset(mtcars, split == "FALSE")
# Training model
logistic_model <- glm(vs ~ wt + disp,
data = train_reg,
family = "binomial")
logistic_model
# Summary
summary(logistic_model)
# Predict test data based on model
predict_reg <- predict(logistic_model,
test_reg, type = "response")
predict_reg
# Changing probabilities
predict_reg <- ifelse(predict_reg >0.5, 1, 0)
# Evaluating model accuracy
# using confusion matrix
table(test_reg$vs, predict_reg)
missing_classerr <- mean(predict_reg != test_reg$vs)
print(paste('Accuracy =', 1 - missing_classerr))
# ROC-AUC Curve
ROCPred <- prediction(predict_reg, test_reg$vs)
ROCPer <- performance(ROCPred, measure = "tpr",
x.measure = "fpr")
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc
# Plotting curve
plot(ROCPer)
plot(ROCPer, colorize = TRUE,
print.cutoffs.at = seq(0.1, by = 0.1),
main = "ROC CURVE")
abline(a = 0, b = 1)
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)
predict_reg
length(iris_1)
length(iris)
iris
iris_1 <- iris[, 1:4]
iris_1
plot(cars)
library(dplyr)
data(iris)
# Structure
str(iris)
iris
iris_1 <- iris[, 1:4]
iris_1
length(iris_1)
length(iris)
model <- kmeans(iris_1, centers = 3, nstart = 20)
model
model$cluster
cm <- table(iris$Species, model$cluster)
cm
plot(iris_1[c("Sepal.Length", "Sepal.Width")])
plot(iris_1[c("Sepal.Length", "Sepal.Width")],
col = model$cluster)
plot(iris_1[c("Sepal.Length", "Sepal.Width")],
col =model$cluster,
main = "K-means with 3 clusters")
model$centers
model$centers[, c("Sepal.Length", "Sepal.Width")]
plot(iris_1[c("Sepal.Length", "Sepal.Width")],
col =model$cluster,
main = "K-means with 3 clusters")
model$centers
model$centers[, c("Sepal.Length", "Sepal.Width")]
library(cluster)
y_kmeans <- model$cluster
clusplot(iris_1[, c("Sepal.Length", "Sepal.Width")],
y_kmeans,
main = paste("Cluster iris"),
xlab = 'Sepal.Length',
ylab = 'Sepal.Width')
distance_mat <- dist(mtcars, method = 'euclidean')
distance_mat
# Fitting Hierarchical clustering Model
# to training dataset
set.seed(240)  # Setting seed
Hierar_cl <- hclust(distance_mat, method = "average")
Hierar_cl
# Plotting dendrogram
plot(Hierar_cl)
# Choosing no. of clusters
# Cutting tree by height
abline(h = 110, col = "green")
# Cutting tree by no. of clusters
fit <- cutree(Hierar_cl, k = 3 )
fit
table(fit)
rect.hclust(Hierar_cl, k = 3, border = "green")
